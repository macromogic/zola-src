+++
title = "特征函数凭什么也是傅里叶变换？"
date = 2023-07-03
draft = true

[taxonomies]
categories = ["Notes"]
tags = ["Math"]
+++

一个概率密度函数和自己反复卷积，随着卷积次数的增加，结果越来越接近正态分布。
这正是我们在数理统计中学到的「中心极限定理」。
然而，我们大多数人并不会在课堂上学到这个定理的证明。
维基百科上的证明使用了特征函数的技巧，而且恰好提到了特征函数空间由「傅里叶变换」得到。
提到特征函数，学过线性代数或者离散数学的同学可能会联想到矩阵或者线性齐次递推的特征方程/特征根。这些名字上的相似或许并非巧合。
接下来我将尝试探究这几个看似八竿子打不着的概念之间的联系。感谢[MstMoonshine](https://mstmoonshine.github.io)对本文的帮助！

<!-- more -->

## 线性代数：特征值和“不变子空间”

我们知道，一个$n \times n$的方阵本质上代表着一个从$n$维向量空间到自身的线性变换。
而方阵的相似性揭示了一个重要的等价关系：如果两个方阵$A$和$B$相似，那么它们代表的是同一个线性变换，只是选取的基底不同。
因此，我们不禁好奇：给定一个线性变换，是否能找到一个「最简」的矩阵表示？

假设有线性空间$V$和非平凡子空间$U$，$T$是$V$上的线性变换，如果$T$作用在$U$上的结果仍然在$U$中，那么我们称$U$是$T$的一个**不变子空间**。
不妨设想：如果$V$能“分解”成一系列不变子空间，分别取这些子空间的基底作为$V$的基底，我们就能得到一个分块对角矩阵来表示$T$，每个对角块代表其对应不变子空间上的变换。
不变子空间越“小”，矩阵表示就越“简单”。

（这里的叙述只是为了直观理解矩阵分解的意义，我不希望在这里引入太多严谨定义，否则这篇文章就本末倒置了。）

直观上，不变子空间最“小”就是一维空间，也就是说，对于某方阵$A$和非零向量$v$，我们有$Av = \lambda v$，其中$\lambda$是一个标量。
这个形式想必大家已经不陌生了，$v$和$\lambda$分别是$A$的**特征向量**和**特征值**。
观察到$v$属于$\lambda I-A$的零空间，这告诉我们$A$的所有特征值都是$p(x) = \det(xI-A)$的零点。
这个多项式$p(x)$被称为$A$的**特征多项式**。
我们可以通过求解$p(x) = 0$得到$A$的所有特征值，进而求出$A$的**Jordan标准形**：
$$
J = \mathop{\mathrm{diag}}(J\_{\lambda\_1}, J\_{\lambda\_2}, \dots, J\_{\lambda\_m})
$$
其中$J\_{\lambda\_i}$代表着特征值$\lambda\_i$对应的Jordan块，形如：
$$
\begin{bmatrix}
\lambda\_i & 0 & 0 & \cdots & 0 & 0 \\\\
1 & \lambda\_i & 0 & \cdots & 0 & 0 \\\\
0 & 1 & \lambda\_i & \cdots & 0 & 0 \\\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\\\
0 & 0 & 0 & \cdots & \lambda\_i & 0 \\\\
0 & 0 & 0 & \cdots & 1 & \lambda\_i
\end{bmatrix}
$$

如果$A$恰好满足一些良好的性质，使得每个Jordan块都是$1 \times 1$的，此时$J$就是一个对角矩阵。
我们称这个时候的$A$为**可对角化**的。

至此，我们发现特征多项式在矩阵分解中能帮助快速找到不变子空间。
子空间的不变性可以让一个高维的复杂变换简化成一系列低维的简单变换的组合。
借助矩阵分解，我们可以大幅简化诸如矩阵幂这样的计算。
对于一般的矩阵，我们可以将这个思想推广到奇异值分解上，但这里不再赘述。

## 递推数列：特征方程和线性通解

